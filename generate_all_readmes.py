import os
import datetime
import re
import urllib.parse
from PIL import Image

# è¨­å®š
IMAGE_DIR = 'images'
ROOT_README = 'README.md'
START_MARKER = '<!-- thumbnails-start -->'
END_MARKER = '<!-- thumbnails-end -->'
MAIN_WIDTH = 30 # ä¸»å°è¦½ç¸®åœ–å¤§å°
SUB_WIDTH = 250 # å­ç›®éŒ„åœ–ç‰‡å¯¬åº¦

def get_size_format(b):
    for unit in ["", "K", "M", "G"]:
        if b < 1024: return f"{b:.2f}{unit}B"
        b /= 1024

if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

subdir_links = []

# 1. éæ­·ç›®éŒ„
for root, dirs, files in sorted(os.walk(IMAGE_DIR)):
    folder_path = os.path.normpath(os.path.relpath(root, '.'))
    folder_name = os.path.basename(root)
    
    if folder_path == ".":
        continue

    valid_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp', '.svg'))]
    rel_url = folder_path.replace('\\', '/')
    depth = rel_url.count('/')
    
    # æ¨¹ç‹€ç¸®æ’ç¬¦è™Ÿ
    indent = "ã€€" * depth + ("â”— " if depth > 0 else "ğŸ“‚ ")
    
    # è¦–è¦ºå±¤ç´šï¼šç¬¬ä¸€å±¤ç²—é«”ï¼Œå…¶é¤˜ä»£ç¢¼æ¨£å¼
    if depth == 0:
        display_name = f"{indent}**{folder_name}**"
    else:
        display_name = f"{indent}`{folder_name}`"

    safe_folder_url = urllib.parse.quote(rel_url)

    if valid_files:
        readme_path = os.path.join(root, 'README.md')
        rel_depth = depth + 1
        back_to_root = "../" * rel_depth
        
        # --- ä¿®æ­£ï¼šGitHub ç›¸å®¹ç‰ˆå¤šåœ–å°é¢ ---
        max_previews = 4 # è¡¨æ ¼å…§ä¸¦æ’ 4 å¼µè¼ƒæ•´é½Š
        preview_files = sorted(valid_files)[:max_previews]
        preview_imgs_html = []
        
        for pf in preview_files:
            pf_path_raw = os.path.join(folder_path, pf).replace('\\', '/')
            safe_pf_url = urllib.parse.quote(pf_path_raw)
            # ç§»é™¤æ‰€æœ‰ styleï¼Œåƒ…ä¿ç•™ GitHub æ”¯æ´çš„å±¬æ€§
            preview_imgs_html.append(f'<img src="{safe_pf_url}" width="{MAIN_WIDTH}" height="{MAIN_WIDTH}" align="top">')
        
        # ä½¿ç”¨ &nbsp; ä»£æ›¿ CSS margin é€²è¡Œé–“éš”
        img_row = "&nbsp;".join(preview_imgs_html)
        
        # ä½¿ç”¨ <sub> ç¸®å°å­—é«”é¡¯ç¤ºå‰©é¤˜æ•¸é‡
        more_tag = f'<sub>(+{len(valid_files)-max_previews})</sub>' if len(valid_files) > max_previews else ""
        img_html = f'<a href="{safe_folder_url}/README.md">{img_row}</a> {more_tag}'
        
        subdir_links.append(f"| [{display_name}]({safe_folder_url}/README.md) | {img_html} | `{len(valid_files)} Items` |")

        # ç”Ÿæˆå­ README
        sub_content = [f"# ğŸ–¼ï¸ {folder_name}\n", f"[â¬…ï¸ è¿”å›ä¸»ç›®éŒ„]({back_to_root}{ROOT_README})\n", "| é è¦½ | è³‡è¨Š |", "| :--- | :--- |"]
        for f in sorted(valid_files):
            safe_f = urllib.parse.quote(f)
            sub_content.append(f'| <a href="{safe_f}"><img src="{safe_f}" width="{SUB_WIDTH}"></a> | **{f}** |')
        
        with open(readme_path, 'w', encoding='utf-8') as f_out:
            f_out.write("\n".join(sub_content))
    else:
        if folder_name != IMAGE_DIR:
            subdir_links.append(f"| {display_name} | ğŸ“ (è³‡æ–™å¤¾) | - |")

# 2. æ›´æ–°æ ¹ç›®éŒ„ README
if not subdir_links:
    nav_table_text = "\nç›®å‰ `images/` ä¸­é‚„æ²’æœ‰å…§å®¹ã€‚\n"
else:
    tree_table = ["## ğŸ“‚ ç´ æç›®éŒ„æ¨¹ç‹€å°è¦½\n", "| ç›®éŒ„è·¯å¾‘ | å°é¢é è¦½ | çµ±è¨ˆ |", "| :--- | :---: | :---: |"] + subdir_links
    nav_table_text = "\n".join(tree_table)

new_nav_section = f"{START_MARKER}\n{nav_table_text}\n{END_MARKER}"

if os.path.exists(ROOT_README):
    with open(ROOT_README, 'r', encoding='utf-8') as f_in:
        content = f_in.read()
    if START_MARKER in content:
        content = re.sub(f"{START_MARKER}.*?{END_MARKER}", new_nav_section, content, flags=re.DOTALL)
    else:
        content += f"\n\n{new_nav_section}"
else:
    header = "# ğŸ¨ æˆ‘çš„è¨­è¨ˆç´ æåº«"
    content = f"{header}\n\n{new_nav_section}\n\n---\n*Last Sync: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}*"

with open(ROOT_README, 'w', encoding='utf-8') as f_out:
    f_out.write(content)
