import os
import datetime
import re
import urllib.parse
from PIL import Image

# è¨­å®š
IMAGE_DIR = 'images'
ROOT_README = 'README.md'
START_MARKER = '<!-- thumbnails-start -->'
END_MARKER = '<!-- thumbnails-end -->'
MAIN_WIDTH = 30 # ä¸»å°è¦½ç¸®åœ–å¤§å°
SUB_WIDTH = 250 # å­ç›®éŒ„åœ–ç‰‡é è¦½å¯¬åº¦é–å®š
REPO_NAME = os.getenv('GITHUB_REPOSITORY', 'ä½ çš„å¸³è™Ÿ/ä½ çš„å€‰åº«å')
BRANCH = 'main' 
IMG_EXTENSIONS = ('.png', '.jpg', '.jpeg', '.gif', '.webp', '.svg')

def get_size_format(b):
    for unit in ["", "K", "M", "G"]:
        if b < 1024: return f"{b:.2f}{unit}B"
        b /= 1024

if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

subdir_links = []

# 1. éæ­·ç›®éŒ„ (å¾ IMAGE_DIR æ ¹éƒ¨é–‹å§‹ï¼Œä¸è·³é)
for root, dirs, files in sorted(os.walk(IMAGE_DIR)):
    folder_path = os.path.normpath(root) # ç›´æ¥ä½¿ç”¨ root
    folder_name = os.path.basename(root)
    
    # è¨ˆç®—ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„çš„è·¯å¾‘
    rel_url = folder_path.replace('\\', '/')
    # è¨ˆç®—æ·±åº¦ï¼š'images' ç‚º 0, 'images/3Ds' ç‚º 1
    depth = rel_url.replace(IMAGE_DIR, '').strip('/').count('/')
    if rel_url == IMAGE_DIR:
        depth = 0
    else:
        depth = rel_url.replace(IMAGE_DIR, '').strip('/').count('/') + 1

    valid_files = [f for f in files if f.lower().endswith(IMG_EXTENSIONS)]
    
    indent = "ã€€" * depth + ("â”— " if depth > 0 else "ğŸ“‚ ")
    display_name = f"{indent}**{folder_name}**" if depth == 0 else f"{indent}`{folder_name}`"
    safe_folder_url = urllib.parse.quote(rel_url)

    # --- æº–å‚™ç”Ÿæˆ README ---
    readme_path = os.path.join(root, '{ROOT_README}')
    # è¨ˆç®—å›æ ¹ç›®éŒ„å±¤ç´šï¼šimages/ éœ€è¦ ../, images/sub/ éœ€è¦ ../../
    back_depth = rel_url.count('/') + 1
    back_to_root = "../" * back_depth

    # --- ç”Ÿæˆå±¤ç´šéºµåŒ…å±‘ ---
    path_parts = rel_url.split('/')
    breadcrumb_links = [f"[ğŸ  ä¸»ç›®éŒ„]({back_to_root}{ROOT_README})"]
    for i in range(len(path_parts)):
        part_name = path_parts[i]
        if i == len(path_parts) - 1:
            breadcrumb_links.append(f"**{part_name}**")
        else:
            steps_back = len(path_parts) - 1 - i
            link_path = "../" * steps_back + "{ROOT_README}"
            breadcrumb_links.append(f"[{part_name}]({link_path})")
    breadcrumb_str = " / ".join(breadcrumb_links)

    width_lock = '<img src="https://raw.githubusercontent.com" width="250" height="1">'

    if valid_files:
        # --- ä¸»ç›®éŒ„é è¦½é‚è¼¯ ---
        max_previews = 4
        preview_files = sorted(valid_files)[:max_previews]
        preview_imgs_html = [f'<img src="{urllib.parse.quote(os.path.join(rel_url, pf).replace("\\", "/"))}" width="{MAIN_WIDTH}" height="{MAIN_WIDTH}" align="top">' for pf in preview_files]
        img_row = "&nbsp;".join(preview_imgs_html)
        more_tag = f'<sub>(+{len(valid_files)-max_previews})</sub>' if len(valid_files) > max_previews else ""
        img_html = f'{img_row} <a href="{safe_folder_url}/{ROOT_README}">{more_tag}</a>'
        
        subdir_links.append(f"| [{display_name}]({safe_folder_url}/README.md) | {img_html} | `{len(valid_files)} Items` |")

        sub_content = [
            f"# ğŸ–¼ï¸ ç´ æåˆ†é¡ï¼š{folder_name}\n",
            f"> {breadcrumb_str}\n",
            f"æœ¬ç›®éŒ„å…±æœ‰ `{len(valid_files)}` å€‹æª”æ¡ˆ\n",
            f"| ğŸ¨ é è¦½ (é»æ“Šæ”¾å¤§)<br>{width_lock} | ğŸ“‹ æª”æ¡ˆè©³ç´°è³‡è¨Šèˆ‡é€£çµ |",
            "| :--- | :--- |"
        ]
        
        for f in sorted(valid_files):
            f_path = os.path.join(root, f)
            safe_f = urllib.parse.quote(f)
            safe_repo = REPO_NAME.lower()
            try:
                stat = os.stat(f_path)
                size = get_size_format(stat.st_size)
                mtime = datetime.datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d')
                
                if f.lower().endswith('.svg'):
                    spec = "âœ¨ **æ ¼å¼:** `Vector (SVG)`"
                else:
                    with Image.open(f_path) as img:
                        w, h = img.size
                    spec = f"ğŸ–¼ï¸ **å°ºå¯¸:** `{w}x{h} px`"

                cdn_url = f"https://cdn.jsdelivr.net/gh/{safe_repo}@{BRANCH}/{urllib.parse.quote(rel_url)}/{safe_f}"
                copy_md = f"![{f}]({cdn_url})"

                details = (
                    f"**ğŸ“‚ æª”å:** `{f}`<br>"
                    f"{spec}<br>"
                    f"âš–ï¸ **å¤§å°:** `{size}`<br>"
                    f"ğŸ“… **æ›´æ–°:** `{mtime}`<br><br>"
                    f"ğŸš€ **jsDelivr Markdown:**<br>`{copy_md}`<br>"
                    f"ğŸ”— **ç›´æ¥é€£çµ (Url):**<br><code>{cdn_url}</code><br>"
                    f"ğŸ“¥ [æª¢è¦–åŸå§‹æª”]({safe_f})"
                )
                
                img_tag = f'<a href="{safe_f}"><img src="{safe_f}" width="{SUB_WIDTH}" alt="{f}"></a>'
                sub_content.append(f"| {img_tag} | {details} |")
            except Exception as e:
                sub_content.append(f"| `{f}` | âš ï¸ ç„¡æ³•è®€å–è©³ç´°è³‡è¨Š |")
        
        with open(readme_path, 'w', encoding='utf-8') as f_out:
            f_out.write("\n".join(sub_content))
    else:
        # --- è™•ç†ç„¡åœ–ç‰‡çš„å°è¦½å±¤ (åŒ…å« images/ æ ¹ç›®éŒ„) ---
        if folder_path != IMAGE_DIR:
            subdir_links.append(f"| [{display_name}]({safe_folder_url}/README.md) | ğŸ“ (å°è¦½å±¤) | - |")
            
        sub_content = [
            f"# ğŸ“‚ ç›®éŒ„ï¼š{folder_name}\n",
            f"> {breadcrumb_str}\n",
            "æ­¤ç›®éŒ„ç›®å‰æ²’æœ‰ç›´æ¥å­˜æ”¾åœ–ç‰‡ï¼Œè«‹é¸æ“‡ä¸‹æ–¹å­åˆ†é¡ï¼š\n",
            "### ğŸ—‚ï¸ å­åˆ†é¡åˆ—è¡¨\n",
            "| åˆ†é¡åç¨± | å°é¢é è¦½ | çµ±è¨ˆ |",
            "| :--- | :--- | :--- |"
        ]
        
        has_sub = False
        for d in sorted(dirs):
            if not d.startswith('.'):
                has_sub = True
                sub_dir_path = os.path.join(root, d)
                
                # éæ­·å­è³‡æ–™å¤¾æ‰¾åœ–ç‰‡ç•¶å°é¢
                sub_valid_files = []
                for sub_root, _, sub_files in os.walk(sub_dir_path):
                    sub_valid_files.extend([os.path.join(sub_root, sf) for sf in sub_files if sf.lower().endswith(IMG_EXTENSIONS)])
                
                # è£½ä½œå­åˆ†é¡çš„å°é¢ HTML
                if sub_valid_files:
                    sub_preview_count = 20
                    # å–å¾—å‰å¹¾å¼µåœ–çš„è·¯å¾‘ä¸¦è½‰ç‚º URL
                    previews = sorted(sub_valid_files)[:sub_preview_count]
                    previews_html = []
                    for p in previews:
                        # é€™è£¡è¦è¨ˆç®—ç›¸å°æ–¼ç•¶å‰ README çš„è·¯å¾‘
                        rel_p = os.path.relpath(p, root).replace('\\', '/')
                        previews_html.append(f'<img src="{urllib.parse.quote(rel_p)}" width="{MAIN_WIDTH}" height="{MAIN_WIDTH}" align="top">')
                    
                    sub_img_row = "&nbsp;".join(previews_html)
                    sub_count_tag = f"å…± `{len(sub_valid_files)}` å¼µ"
                else:
                    sub_img_row = "ğŸ“ *(ç„¡åœ–ç‰‡)*"
                    sub_count_tag = "-"

                sub_content.append(f"| [ğŸ“ **{d}**]({urllib.parse.quote(d)}/README.md) | {sub_img_row} | {sub_count_tag} |")
        
        if not has_sub:
            sub_content = sub_content[:4] # ç§»é™¤è¡¨æ ¼é ­éƒ¨
            sub_content.append("*(æ­¤ç›®éŒ„ç›®å‰ç‚ºç©º)*")

        with open(readme_path, 'w', encoding='utf-8') as f_out:
            f_out.write("\n".join(sub_content))


# 2. æ›´æ–°æ ¹ç›®éŒ„ README
tree_table = ["## ğŸ“‚ ç´ æç›®éŒ„æ¨¹ç‹€å°è¦½\n", "| ç›®éŒ„è·¯å¾‘ | å°é¢é è¦½ | çµ±è¨ˆ |", "| :--- | :---: | :---: |"] + subdir_links
nav_table_text = "\n".join(tree_table)
new_nav_section = f"{START_MARKER}\n{nav_table_text}\n{END_MARKER}"

if os.path.exists(ROOT_README):
    with open(ROOT_README, 'r', encoding='utf-8') as f_in:
        content = f_in.read()
    content = re.sub(f"{START_MARKER}.*?{END_MARKER}", new_nav_section, content, flags=re.DOTALL) if START_MARKER in content else content + f"\n\n{new_nav_section}"
else:
    content = f"# ğŸ¨ ç´ æåº«\n\n{new_nav_section}"

with open(ROOT_README, 'w', encoding='utf-8') as f_out:
    f_out.write(content)
print("Done! All READMEs (including images/{ROOT_README}) generated.")


















