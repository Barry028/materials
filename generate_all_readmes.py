import os
import datetime
import re
import urllib.parse
from PIL import Image

# è¨­å®š
IMAGE_DIR = 'images'
ROOT_README = 'README.md'
START_MARKER = '<!-- thumbnails-start -->'
END_MARKER = '<!-- thumbnails-end -->'
MAIN_WIDTH = 30 # ä¸»å°è¦½ç¸®åœ–å¤§å°
SUB_WIDTH = 250 # å­ç›®éŒ„åœ–ç‰‡é è¦½å¯¬åº¦
# è‡ªå‹•æŠ“å– GitHub å€‰åº«åç¨±ï¼Œè‹¥åœ¨æœ¬æ©ŸåŸ·è¡Œè«‹ä¿®æ”¹é è¨­å€¼
REPO_NAME = os.getenv('GITHUB_REPOSITORY', 'ä½ çš„å¸³è™Ÿ/ä½ çš„å€‰åº«å')
BRANCH = 'main' # ç¢ºä¿é€™æ˜¯æ‚¨çš„ä¸»åˆ†æ”¯åç¨±

def get_size_format(b):
    for unit in ["", "K", "M", "G"]:
        if b < 1024: return f"{b:.2f}{unit}B"
        b /= 1024

if not os.path.exists(IMAGE_DIR):
    os.makedirs(IMAGE_DIR)

subdir_links = []

# 1. éæ­·ç›®éŒ„
for root, dirs, files in sorted(os.walk(IMAGE_DIR)):
    folder_path = os.path.normpath(os.path.relpath(root, '.'))
    folder_name = os.path.basename(root)
    
    if folder_path == ".":
        continue

    valid_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp', '.svg'))]
    rel_url = folder_path.replace('\\', '/')
    depth = rel_url.count('/')
    
    # æ¨¹ç‹€ç¸®æ’ç¬¦è™Ÿ
    indent = "ã€€" * depth + ("â”— " if depth > 0 else "ğŸ“‚ ")
    
    # è¦–è¦ºå±¤ç´šï¼šç¬¬ä¸€å±¤ç²—é«”ï¼Œå…¶é¤˜ä»£ç¢¼æ¨£å¼
    if depth == 0:
        display_name = f"{indent}**{folder_name}**"
    else:
        display_name = f"{indent}`{folder_name}`"

    safe_folder_url = urllib.parse.quote(rel_url)

    if valid_files:
        readme_path = os.path.join(root, 'README.md')
        rel_depth = depth + 1
        back_to_root = "../" * rel_depth
        
        # --- ä¸»ç›®éŒ„å°é¢é è¦½ (ä¸¦æ’ç¸®åœ–) ---
        max_previews = 4
        preview_files = sorted(valid_files)[:max_previews]
        preview_imgs_html = [f'<img src="{urllib.parse.quote(os.path.join(folder_path, pf).replace("\\", "/"))}" width="{MAIN_WIDTH}" height="{MAIN_WIDTH}" align="top">' for pf in preview_files]
        img_row = "&nbsp;".join(preview_imgs_html)
        more_tag = f'<sub>(+{len(valid_files)-max_previews})</sub>' if len(valid_files) > max_previews else ""
        img_html = f'{img_row} <a href="{safe_folder_url}/README.md">{more_tag}</a>'
        
        subdir_links.append(f"| [{display_name}]({safe_folder_url}/README.md) | {img_html} | `{len(valid_files)} Items` |")

        # --- ğŸ’¡ å¼·åŒ–ç‰ˆï¼šå‹•æ…‹ç”Ÿæˆå®Œæ•´å±¤ç´šéºµåŒ…å±‘ ---
        path_parts = folder_path.split(os.sep)
        breadcrumb_links = [f"[ğŸ  ä¸»ç›®éŒ„]({back_to_root}{ROOT_README})"]
        for i in range(len(path_parts)):
            part_name = path_parts[i]
            if i == len(path_parts) - 1:
                breadcrumb_links.append(f"**{part_name}**")
            else:
                steps_back = len(path_parts) - 1 - i
                link_path = "../" * steps_back + "README.md"
                breadcrumb_links.append(f"[{part_name}]({link_path})")
        breadcrumb_str = " / ".join(breadcrumb_links)

        # --- å­ç›®éŒ„ README ç¾åŒ– (å¡ç‰‡æ¨£å¼ + CDN è¤‡è£½å€å¡Š) ---
        sub_content = [
            f"# ğŸ–¼ï¸ ç´ æåˆ†é¡ï¼š{folder_name}\n",
            f"> {breadcrumb_str}\n",
            f"æœ¬ç›®éŒ„å…±æœ‰ `{len(valid_files)}` å€‹æª”æ¡ˆ\n",
            "| ğŸ¨ é è¦½ (é»æ“Šæ”¾å¤§) | ğŸ“‹ æª”æ¡ˆè©³ç´°è³‡è¨Šèˆ‡é€£çµ |",
            "| :--- | :--- |"
        ]
        
        for f in sorted(valid_files):
            f_path = os.path.join(root, f)
            rel_img_path = os.path.relpath(f_path, '.').replace('\\', '/')
            safe_rel_path = urllib.parse.quote(rel_img_path)
            safe_f = urllib.parse.quote(f)
            safe_repo = REPO_NAME.lower()
            try:
                stat = os.stat(f_path)
                size = get_size_format(stat.st_size)
                mtime = datetime.datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d')
                
                if f.lower().endswith('.svg'):
                    spec = "âœ¨ **æ ¼å¼:** `Vector (SVG)`"
                else:
                    with Image.open(f_path) as img:
                        w, h = img.size
                    spec = f"ğŸ–¼ï¸ **å°ºå¯¸:** `{w}x{h} px`"

                cdn_url = f"https://cdn.jsdelivr.net/gh{safe_repo}@{BRANCH}/{safe_rel_path}"
                copy_md = f"![{f}]({cdn_url})"

                details = (
                    f"**ğŸ“‚ æª”å:** `{f}`<br>"
                    f"{spec}<br>"
                    f"âš–ï¸ **å¤§å°:** `{size}` | ğŸ“… **æ›´æ–°:** `{mtime}`<br>"
                    f"<br>ğŸš€ **jsDelivr Markdown:**<br>`{copy_md}`<br>"
                    f"ğŸ”— **ç›´æ¥é€£çµ (Url):**<br>`{cdn_url}`<br>"
                    f"ğŸ“¥ [æª¢è¦–åŸå§‹æª”]({safe_f})"
                )
                
                img_tag = f'<a href="{safe_f}"><img src="{safe_f}" width="{SUB_WIDTH}" alt="{f}"></a>'
                sub_content.append(f"| {img_tag} | {details} |")
            except Exception as e:
                print(f"Error processing {f}: {e}")
                sub_content.append(f"| `{f}` | âš ï¸ ç„¡æ³•è®€å–è©³ç´°è³‡è¨Š |")
        
        with open(readme_path, 'w', encoding='utf-8') as f_out:
            f_out.write("\n".join(sub_content))
    else:
        # ä¿ç•™çˆ¶è³‡æ–™å¤¾åç¨±ï¼ˆå¦‚ 3Dsï¼‰
        if folder_name != IMAGE_DIR:
            subdir_links.append(f"| {display_name} | ğŸ“ (è³‡æ–™å¤¾) | - |")

# 2. æ›´æ–°æ ¹ç›®éŒ„ README
if not subdir_links:
    nav_table_text = "\nç›®å‰ `images/` ä¸­é‚„æ²’æœ‰å…§å®¹ã€‚\n"
else:
    tree_table = ["## ğŸ“‚ ç´ æç›®éŒ„æ¨¹ç‹€å°è¦½\n", "| ç›®éŒ„è·¯å¾‘ | å°é¢é è¦½ | çµ±è¨ˆ |", "| :--- | :---: | :---: |"] + subdir_links
    nav_table_text = "\n".join(tree_table)

new_nav_section = f"{START_MARKER}\n{nav_table_text}\n{END_MARKER}"

if os.path.exists(ROOT_README):
    with open(ROOT_README, 'r', encoding='utf-8') as f_in:
        content = f_in.read()
    if START_MARKER in content:
        content = re.sub(f"{START_MARKER}.*?{END_MARKER}", new_nav_section, content, flags=re.DOTALL)
    else:
        content += f"\n\n{new_nav_section}"
else:
    header = "# ğŸ¨ æˆ‘çš„è¨­è¨ˆç´ æåº«\né€™æ˜¯ä¸€å€‹å…¨è‡ªå‹•æ›´æ–°çš„ç´ æå°è¦½ç³»çµ±ã€‚"
    content = f"{header}\n\n{new_nav_section}\n\n---\n*Last Sync: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}*"

with open(ROOT_README, 'w', encoding='utf-8') as f_out:
    f_out.write(content)
print(f"Successfully processed {ROOT_README}")
